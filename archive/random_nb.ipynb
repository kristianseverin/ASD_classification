{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible solution to assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a worked solution to assignment 3, training a neural network classifier with ```pytorch```.\n",
    "\n",
    "Please note that this is *not* comprehensive - this is not then only solution, with all others being wrong. This is just a possible solution, based on me having spent some time looking at the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages\n",
    "\n",
    "Note how here I'm using ```TfidfVectorizer()``` instead of ```CountVectorizer()```. This seemed to perform better empirically, producing smoother learning curves and higher accuracies on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T11:45:49.822394Z",
     "iopub.status.busy": "2022-10-13T11:45:49.821695Z",
     "iopub.status.idle": "2022-10-13T11:45:51.478553Z",
     "shell.execute_reply": "2022-10-13T11:45:51.477804Z",
     "shell.execute_reply.started": "2022-10-13T11:45:49.822335Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (20.3.4)\n",
      "Collecting pip\n",
      "  Using cached pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: datasets in /home/coder/.local/lib/python3.9/site-packages (2.7.1)\n",
      "Requirement already satisfied: torch in /home/coder/.local/lib/python3.9/site-packages (1.13.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /home/coder/.local/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/coder/.local/lib/python3.9/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/coder/.local/lib/python3.9/site-packages (from datasets) (2022.5.0)\n",
      "Requirement already satisfied: pandas in /home/coder/.local/lib/python3.9/site-packages (from datasets) (1.4.3)\n",
      "Requirement already satisfied: xxhash in /home/coder/.local/lib/python3.9/site-packages (from datasets) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/coder/.local/lib/python3.9/site-packages (from datasets) (1.23.0)\n",
      "Requirement already satisfied: packaging in /home/coder/.local/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: multiprocess in /home/coder/.local/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: responses<0.19 in /home/coder/.local/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/coder/.local/lib/python3.9/site-packages (from datasets) (8.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/coder/.local/lib/python3.9/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/coder/.local/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/coder/.local/lib/python3.9/site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /home/coder/.local/lib/python3.9/site-packages (from datasets) (0.11.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/coder/.local/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/coder/.local/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/coder/.local/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/coder/.local/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in /home/coder/.local/lib/python3.9/site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.34.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (52.0.0)\n",
      "Requirement already satisfied: filelock in /home/coder/.local/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/coder/.local/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/coder/.local/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/coder/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/coder/.local/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/coder/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/coder/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/coder/.local/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/coder/.local/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/coder/.local/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/coder/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-22.3.1\n"
     ]
    }
   ],
   "source": [
    "# system tools\n",
    "import os\n",
    "\n",
    "# pytorch\n",
    "os.system('pip install --upgrade pip datasets torch')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# huggingface datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# scikit learn tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# plotting tools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Neural Network model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how here I'm using a _ReLU_ activation function. After experimenting a little, I found that _ReLU_ was overfitting much less quickly than using _Sigmoid_ activation functions. The final layer is still _Sigmoid_ as we're trying to make a binary prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T11:45:52.446986Z",
     "iopub.status.busy": "2022-10-13T11:45:52.446375Z",
     "iopub.status.idle": "2022-10-13T11:45:52.458121Z",
     "shell.execute_reply": "2022-10-13T11:45:52.457184Z",
     "shell.execute_reply.started": "2022-10-13T11:45:52.446932Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Neural network model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(n_input_features, 100)\n",
    "        self.linear2 = nn.Linear(100, 10)\n",
    "        self.linear3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        leaky_relu = nn.LeakyReLU(0.2)\n",
    "        # Linear -> ReLU\n",
    "        x = self.linear1(x)\n",
    "        x = leaky_relu(x)\n",
    "        # Linear -> ReLU\n",
    "        x = self.linear2(x)\n",
    "        x = leaky_relu(x)\n",
    "        # Linear -> Sigmoid\n",
    "        x = self.linear3(x)\n",
    "        y_pred = torch.sigmoid(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Logistic regression model\n",
    "# class Model(nn.Module):\n",
    "#     \"\"\" class initializing a simple logistic regression classifier\n",
    "#     \"\"\"\n",
    "#     def __init__(self, n_input_features):\n",
    "#          super().__init__()\n",
    "#          self.linear = torch.nn.Linear(n_input_features, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.linear(x)\n",
    "#         y_pred = torch.sigmoid(x)\n",
    "#         return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load data__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, I decided to use the \"Rotten Tomatoes\" dataset from Huggingface. Technically, any other ```Huggingface``` dataset should fit in here, as long as it has training-validation-test datasets and binary labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T11:45:53.916946Z",
     "iopub.status.busy": "2022-10-13T11:45:53.916187Z",
     "iopub.status.idle": "2022-10-13T11:45:58.969976Z",
     "shell.execute_reply": "2022-10-13T11:45:58.968775Z",
     "shell.execute_reply.started": "2022-10-13T11:45:53.916892Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Import the dataframe\n",
    "# data = pd.read_csv(\"/work/exam/ASD_classification/data/dataframes/data_eigstig_age3_text_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/coder/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d2fe7e5e1c43329e951dbcdd9ad93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "\n",
    "# obtain train, val and test splits\n",
    "train = dataset[\"train\"]\n",
    "val = dataset[\"validation\"]\n",
    "test = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by explicitly separating the different splits in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T11:45:58.981711Z",
     "iopub.status.busy": "2022-10-13T11:45:58.981358Z",
     "iopub.status.idle": "2022-10-13T11:45:58.987989Z",
     "shell.execute_reply": "2022-10-13T11:45:58.986625Z",
     "shell.execute_reply.started": "2022-10-13T11:45:58.981679Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Split dataset into train, test, val (70, 15, 15)\n",
    "# train, test = train_test_split(data, test_size=0.15)\n",
    "# train, val = train_test_split(train, test_size=0.15)\n",
    "\n",
    "# # Turning the split dataframes into dicts\n",
    "# train = Dataset.from_dict(train)\n",
    "# val = Dataset.from_dict(val)\n",
    "# test = Dataset.from_dict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Vectorize__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then define how to use my vectorizer class. I originally trained by using ```lowercase=True```and using removing highly common English words (what are called \"stopwords\" in text mining literature). However, this was a bad idea - the data is already lowercase, and removing stopwords reduced performance. I suspect that this is because I was actually removing a lot of common words which are shared across training and test data, meaning it was harder for the model to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T11:51:48.202285Z",
     "iopub.status.busy": "2022-10-13T11:51:48.201605Z",
     "iopub.status.idle": "2022-10-13T11:51:48.227966Z",
     "shell.execute_reply": "2022-10-13T11:51:48.227198Z",
     "shell.execute_reply.started": "2022-10-13T11:51:48.202228Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2),\n",
    "                            #lowercase=True, \n",
    "                            #stop_words=\"english\", \n",
    "                            max_df=0.9, \n",
    "                            min_df=0.1,\n",
    "                            max_features=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first vectorize the training data and conver the labels to something that ```pytorch``` can use. \n",
    "\n",
    "After than, I transform the validation and test data using the vectorizer that was fit to the training data. Be careful here that you don't use ```.fit_transform()``` on the validation and training data again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T11:51:49.033759Z",
     "iopub.status.busy": "2022-10-13T11:51:49.033563Z",
     "iopub.status.idle": "2022-10-13T11:51:49.428600Z",
     "shell.execute_reply": "2022-10-13T11:51:49.427609Z",
     "shell.execute_reply.started": "2022-10-13T11:51:49.033741Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vectorized training data -> to tensors\n",
    "train_vect = vectorizer.fit_transform(train[\"text\"])\n",
    "train_vect = torch.tensor(train_vect.toarray(), dtype=torch.float)\n",
    "\n",
    "# labels\n",
    "train_label = torch.tensor(list(train[\"label\"]), dtype=torch.float)\n",
    "train_label = train_label.view(train_label.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T11:51:49.430007Z",
     "iopub.status.busy": "2022-10-13T11:51:49.429726Z",
     "iopub.status.idle": "2022-10-13T11:51:49.463608Z",
     "shell.execute_reply": "2022-10-13T11:51:49.463193Z",
     "shell.execute_reply.started": "2022-10-13T11:51:49.429982Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vectorized validation data -> to tensors\n",
    "val_vect = vectorizer.transform(val[\"text\"])\n",
    "val_vect = torch.tensor(val_vect.toarray(), dtype=torch.float)\n",
    "\n",
    "# labels\n",
    "val_label = torch.tensor(list(val[\"label\"]), dtype=torch.float)\n",
    "val_label = val_label.view(val_label.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T11:51:49.465135Z",
     "iopub.status.busy": "2022-10-13T11:51:49.464870Z",
     "iopub.status.idle": "2022-10-13T11:51:49.503738Z",
     "shell.execute_reply": "2022-10-13T11:51:49.503085Z",
     "shell.execute_reply.started": "2022-10-13T11:51:49.465117Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vectorized test data -> to tensors\n",
    "test_vect = vectorizer.transform(test[\"text\"])\n",
    "test_vect = torch.tensor(test_vect.toarray(), dtype=torch.float)\n",
    "\n",
    "# labels\n",
    "test_label = torch.tensor(list(test[\"label\"]), dtype=torch.float)\n",
    "test_label = test_label.view(test_label.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parameters__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then initialise my model just like we did in class last time. The only difference here is that I'm adding a fairly small learning rate to ```ADAM``` to avoid overfitting - note that ```1e-4``` is scientific notation, so that's 0.0001.\n",
    "\n",
    "This learning rate was decided upon through trial and error. We'll see in class soon how we can do _hyperparameter search_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Weights\n",
    "# ## Weights for class 0:\n",
    "# w0 = 2435/(2 * 1730)\n",
    "# ## Weights for class 1:\n",
    "# w1 = 2435/(2 * 705)\n",
    "# #weights = {0 : w0, 1 : w1}\n",
    "# weights = torch.Tensor([0.000000000001])\n",
    "# print(weights.size())\n",
    "# #weights = {0:w0, 1:w1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T11:52:39.193808Z",
     "iopub.status.busy": "2022-10-13T11:52:39.192969Z",
     "iopub.status.idle": "2022-10-13T11:52:39.203543Z",
     "shell.execute_reply": "2022-10-13T11:52:39.202474Z",
     "shell.execute_reply.started": "2022-10-13T11:52:39.193748Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize model\n",
    "n_samples, n_features = train_vect.shape\n",
    "model = Model(n_input_features=n_features)\n",
    "\n",
    "# define loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create empty lists into which I'm going to save the training and validation loss after every epoch. This is because we can actually learn a lot about _how well_ a model is learning by inspecting the loss curves. There's a nice introduction to this idea [here](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/).\n",
    "\n",
    "Note that we could do the same for an _accuracy curve_ - i.e. how much is accuracy improving over time. \n",
    "\n",
    "- How might we implement that?\n",
    "- What would we expect to see if a model is learning well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T11:52:39.962303Z",
     "iopub.status.busy": "2022-10-13T11:52:39.962132Z",
     "iopub.status.idle": "2022-10-13T11:52:39.974454Z",
     "shell.execute_reply": "2022-10-13T11:52:39.973830Z",
     "shell.execute_reply.started": "2022-10-13T11:52:39.962288Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for plotting\n",
    "train_loss_history = []\n",
    "val_loss_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train for 1000 epochs, and the loop here is very similar to what we've worked on in-class. The only difference is that after we've run the backprop and updated the gradients, we then test how well the model performs on the validation data during this epoch.\n",
    "\n",
    "Notice that we need to do two things here - firstly, we set ```torch.no_grad()``` to make sure that we don't accidentally update any gradients that we don't want to update. We also then have to set the model to evaluation mode using ```model.eval()```. This make sure that we don't do a forward pass over the validation data and end up learning from it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T11:52:39.975378Z",
     "iopub.status.busy": "2022-10-13T11:52:39.975209Z",
     "iopub.status.idle": "2022-10-13T11:52:47.377280Z",
     "shell.execute_reply": "2022-10-13T11:52:47.376608Z",
     "shell.execute_reply.started": "2022-10-13T11:52:39.975363Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO:] Training classifier...\n",
      "epoch: 100, loss = 0.6913\n",
      "epoch: 200, loss = 0.6872\n",
      "epoch: 300, loss = 0.6819\n",
      "epoch: 400, loss = 0.6788\n",
      "epoch: 500, loss = 0.6771\n",
      "epoch: 600, loss = 0.6760\n",
      "epoch: 700, loss = 0.6751\n",
      "epoch: 800, loss = 0.6741\n",
      "epoch: 900, loss = 0.6731\n",
      "epoch: 1000, loss = 0.6719\n",
      "[INFO:] Finished traning!\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "epochs = 1000\n",
    "print(\"[INFO:] Training classifier...\")\n",
    "\n",
    "# loop for epochs\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # forward\n",
    "    y_hat = model(train_vect)\n",
    "\n",
    "    # backward\n",
    "    loss = criterion(y_hat, train_label)\n",
    "    train_loss_history.append(loss)\n",
    "\n",
    "    # backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # take step, reset\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Validation Loop \n",
    "    with torch.no_grad(): \n",
    "        # set to eval mode\n",
    "        model.eval() \n",
    "\n",
    "        # make predictions\n",
    "        predicted_outputs = model(val_vect) \n",
    "\n",
    "        # metrics\n",
    "        val_loss = criterion(predicted_outputs, val_label) \n",
    "\n",
    "        # append\n",
    "        val_loss_history.append(val_loss) \n",
    "\n",
    "    # some print to see that it is running\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"epoch: {epoch+1}, loss = {loss.item():.4f}\")\n",
    "\n",
    "print(\"[INFO:] Finished traning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluate__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model has trained, we can then inspect performance. Since we only trained on the train and validation splits, we can then check how our accuracy looks when evaluating the test data. This test data has not been at all during training, so it's completely new to the model. If it performs well on this held out data, that implies that the model has learned to generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T11:52:48.867733Z",
     "iopub.status.busy": "2022-10-13T11:52:48.867555Z",
     "iopub.status.idle": "2022-10-13T11:52:48.881390Z",
     "shell.execute_reply": "2022-10-13T11:52:48.880659Z",
     "shell.execute_reply.started": "2022-10-13T11:52:48.867716Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          TD       0.57      0.55      0.56       533\n",
      "         ASD       0.56      0.58      0.57       533\n",
      "\n",
      "    accuracy                           0.56      1066\n",
      "   macro avg       0.56      0.56      0.56      1066\n",
      "weighted avg       0.56      0.56      0.56      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot\n",
    "predicted = model(test_vect).detach().numpy()\n",
    "print(classification_report(test_label, \n",
    "                            np.where(predicted > 0.5, 1, 0),\n",
    "                            target_names = [\"TD\", \"ASD\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also produce a simple plot showing how training and validation loss decrease over time. The blue line is the training loss; orange is the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T11:52:48.882400Z",
     "iopub.status.busy": "2022-10-13T11:52:48.882196Z",
     "iopub.status.idle": "2022-10-13T11:52:49.009984Z",
     "shell.execute_reply": "2022-10-13T11:52:49.009278Z",
     "shell.execute_reply.started": "2022-10-13T11:52:48.882380Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f718962a1c0>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = [val.item() for val in train_loss_history]\n",
    "val_loss = [val.item() for val in val_loss_history]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_loss)\n",
    "ax.plot(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given the loss curves and the classification report, how well is this model performing?\n",
    "- If we wanted to make improvements, what might we want to change?\n",
    "- How do we make principled decisions about which hyperparameters to change?\n",
    "  - Hint: One way to do it to just use [brute force](https://towardsdatascience.com/grid-search-for-model-tuning-3319b259367e)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
