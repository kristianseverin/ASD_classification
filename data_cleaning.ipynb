{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook works for loading and reshaping the Eigsti and Nadig datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pylangacq\n",
      "  Downloading pylangacq-0.17.0-py3-none-any.whl (65 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.2/65.2 kB 688.2 kB/s eta 0:00:00\n",
      "Collecting tabulate[widechars]>=0.8.9\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: requests>=2.18.0 in /home/coder/.local/lib/python3.9/site-packages (from pylangacq) (2.28.1)\n",
      "Requirement already satisfied: python-dateutil>=2.0.0 in /home/coder/.local/lib/python3.9/site-packages (from pylangacq) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/coder/.local/lib/python3.9/site-packages (from python-dateutil>=2.0.0->pylangacq) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.18.0->pylangacq) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.18.0->pylangacq) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.18.0->pylangacq) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.18.0->pylangacq) (2022.6.15)\n",
      "Requirement already satisfied: wcwidth in /home/coder/.local/lib/python3.9/site-packages (from tabulate[widechars]>=0.8.9->pylangacq) (0.2.5)\n",
      "Installing collected packages: tabulate, pylangacq\n",
      "Successfully installed pylangacq-0.17.0 tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "# LOADING THE REQUIRED PACKAGES\n",
    "import os\n",
    "os.system('pip install pylangacq')\n",
    "import pylangacq \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITING A FUNCTION FOR LOADING DATA\n",
    "# This function loads each file in the directory individually, and turns it into a dataframe. Then it creates columns for age,\n",
    "# id, and group. Finally, it binds the individual dataframes together.\n",
    "\n",
    "## Accessing single files\n",
    "def dataload(datapath):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for subject in os.listdir(datapath):\n",
    "        #print(subject)\n",
    "        pylang_obj = pylangacq.read_chat(path = datapath, match = subject)\n",
    "        d = pd.DataFrame(pylang_obj.utterances())\n",
    "        d[\"age\"] = pylang_obj.ages(months=True)[0]\n",
    "        d[\"id\"] = pylang_obj.headers()[0]['PID']\n",
    "        d[\"group\"] = pylang_obj.headers()[0]['Participants']['CHI']['group']\n",
    "        df = pd.concat([df, d])\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNNING THE DATALOAD FUNCTION ON ALL FILES\n",
    "all_data = dataload(os.path.join(\"/work\", \"exam\", \"ASD_classification\", \"data\", \"corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A COLUMN WHERE EACH UTTERANCE IS A STRING\n",
    "# Accessing the word-keys in the nested dicts in the tokens column and appending them to a string in a new tokens column\n",
    "\n",
    "words = \"\"\n",
    "tokens2 = []\n",
    "\n",
    "for row in all_data['tokens']:\n",
    "    for list in row:\n",
    "        #print(list['word'])\n",
    "        words += list['word'] + \" \"\n",
    "    tokens2.append(words)\n",
    "    words = \"\"\n",
    "\n",
    "all_data['tokens2'] = tokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING THE DF\n",
    "# Dropping unnecessary columns\n",
    "all_data = all_data.drop(columns=['tokens'])\n",
    "all_data = all_data.drop(columns=['tiers'])\n",
    "all_data = all_data.drop(columns=['time_marks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TD' 'DD' 'ASD' 'TYP']\n",
      "['TD' 'ASD']\n"
     ]
    }
   ],
   "source": [
    "# We can read from the description of the datasets on talkbank.org - and see it here - that Eigstig annotated the typically\n",
    "# developing children with TD and Nadig used TYP. For consistency, we will recode all variables that are grouped TYP to TD.\n",
    "# Eigstig also has a group called DD (for developmental delay). These children have developmental delay, but not ASD. This group\n",
    "# will be filtered out.\n",
    "print(all_data['group'].unique())\n",
    "\n",
    "# Recoding TYP to TD\n",
    "all_data = all_data.replace('TYP','TD')\n",
    "\n",
    "# Dropping the rows from the DD group\n",
    "all_data = all_data[all_data.group != 'DD']\n",
    "\n",
    "# Checking the variables\n",
    "print(all_data['group'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>age</th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>tokens2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INV1</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>we've got sort of a bumblebee theme here becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INV1</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INV1</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>mmmm .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INV1</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>hm .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INV1</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>and you know what ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>MOT</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>oh that feels great .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>CHI</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>haircut .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>MOT</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>thank_you .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>CHI</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>CHI</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>now I make some my something else .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24556 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant        age                  id group  \\\n",
       "0          INV1  45.633333  11312/a-00032743-1    TD   \n",
       "1          INV1  45.633333  11312/a-00032743-1    TD   \n",
       "2          INV1  45.633333  11312/a-00032743-1    TD   \n",
       "3          INV1  45.633333  11312/a-00032743-1    TD   \n",
       "4          INV1  45.633333  11312/a-00032743-1    TD   \n",
       "..          ...        ...                 ...   ...   \n",
       "309         MOT  28.800000  11312/a-00005262-1    TD   \n",
       "310         CHI  28.800000  11312/a-00005262-1    TD   \n",
       "311         MOT  28.800000  11312/a-00005262-1    TD   \n",
       "312         CHI  28.800000  11312/a-00005262-1    TD   \n",
       "313         CHI  28.800000  11312/a-00005262-1    TD   \n",
       "\n",
       "                                               tokens2  \n",
       "0    we've got sort of a bumblebee theme here becau...  \n",
       "1                                                   .   \n",
       "2                                              mmmm .   \n",
       "3                                                hm .   \n",
       "4                                 and you know what ?   \n",
       "..                                                 ...  \n",
       "309                             oh that feels great .   \n",
       "310                                         haircut .   \n",
       "311                                       thank_you .   \n",
       "312                                                 .   \n",
       "313               now I make some my something else .   \n",
       "\n",
       "[24556 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data\n",
    "\n",
    "# Possible issue: In the Nadig data, there are a lot of rows/utterances that consist only of a punctuation, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING THE DF AS A CSV FILE\n",
    "all_data.to_csv('all_data.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INV1' 'INV2' 'MOT' 'CHI' 'FAT' 'INV' 'MOM']\n"
     ]
    }
   ],
   "source": [
    "print(all_data['participant'].unique())\n",
    "\n",
    "# Dropping the rows that are not participant == CHI\n",
    "CHI_data = all_data[all_data.participant == 'CHI']\n",
    "\n",
    "# Dropping the column participant (since this is always CHI now)\n",
    "CHI_data = CHI_data.drop(columns=['participant'])\n",
    "\n",
    "CHI_data.to_csv('CHI_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>tokens2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>no Mama no not just ponytail .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>I just your hair .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>haircut .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>now I make some my something else .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8353 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age                  id group                               tokens2\n",
       "50   45.633333  11312/a-00032743-1    TD                                    . \n",
       "61   45.633333  11312/a-00032743-1    TD                                    . \n",
       "72   45.633333  11312/a-00032743-1    TD                                    . \n",
       "86   45.633333  11312/a-00032743-1    TD                                    . \n",
       "88   45.633333  11312/a-00032743-1    TD                                    . \n",
       "..         ...                 ...   ...                                   ...\n",
       "304  28.800000  11312/a-00005262-1    TD       no Mama no not just ponytail . \n",
       "306  28.800000  11312/a-00005262-1    TD                   I just your hair . \n",
       "310  28.800000  11312/a-00005262-1    TD                            haircut . \n",
       "312  28.800000  11312/a-00005262-1    TD                                    . \n",
       "313  28.800000  11312/a-00005262-1    TD  now I make some my something else . \n",
       "\n",
       "[8353 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHI_data\n",
    "\n",
    "# Tokens2 has a lot of columns that have only a \".\". I used the utterances() function to load the data, so it is\n",
    "# only the verbal utterances that are included in this dataset. If we look in the original dataset, we see that\n",
    "# the \".\"'s indicate rows where the child communicated non-verbally, e.g. by nodding, shaking their head, counting\n",
    "# on their fingers, etc. The frequecy of these in the dataset could likely also tell us something about the differ-\n",
    "# ence in language/communication between TD and ASD children, but for our purpose, we will remove these from the \n",
    "# dataset, because we are looking at verbal language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data to fit the LogReg and NN classifiers\n",
    "This means that the data must be in a shape of a class, which contains a tuple of three dictionaries: taining, validation, and test data. Inside each subset is a tuple with a dictionary which contains features (list) and number of rows (value). Features is a list which contains text and labels - so for our data, these would be tokens2, age, and group/diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Class with functions - not working\n",
    "# class createDatasetDict:\n",
    "\n",
    "#     def split_data(self, data):\n",
    "#         self.data = data\n",
    "\n",
    "#         # Split dataset into train, test, val (70, 15, 15)\n",
    "#         train, test = train_test_split(df, test_size=0.15)\n",
    "#         train, val = train_test_split(train, test_size=0.15)\n",
    "\n",
    "#         # Turning the split dataframes into dicts\n",
    "#         train = Dataset.from_dict(train)\n",
    "#         val = Dataset.from_dict(val)\n",
    "#         test = Dataset.from_dict(test)\n",
    "\n",
    "#         return(train, val, test)\n",
    "\n",
    "\n",
    "#     def create_dicts(self, train, val, test):\n",
    "#         corpus_dict = datasets.DatasetDict({\n",
    "#             \"train\":self.train, \n",
    "#             \"val\":self.val, \n",
    "#             \"test\":self.test\n",
    "#             })\n",
    "    \n",
    "#         return(corpus_dict)\n",
    "\n",
    "# if __name__==\"__main__\":\n",
    "#     createDatasetDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class createDatasetDict:\n",
    "\n",
    "    # Split dataset into train, test, val (70, 15, 15)\n",
    "    train, test = train_test_split(df, test_size=0.15)\n",
    "    train, val = train_test_split(train, test_size=0.15)\n",
    "\n",
    "    # Turning the split dataframes into dicts\n",
    "    train = Dataset.from_dict(train)\n",
    "    val = Dataset.from_dict(val)\n",
    "    test = Dataset.from_dict(test)\n",
    "\n",
    "    corpus_dict = datasets.DatasetDict({\n",
    "        \"train\":train, \n",
    "        \"val\":val, \n",
    "        \"test\":test\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "data = pd.read_csv(\"/work/exam/ASD_classification/CHI_data.csv\")\n",
    "\n",
    "dd = createDatasetDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['age', 'id', 'group', 'tokens2'],\n",
      "        num_rows: 6035\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['age', 'id', 'group', 'tokens2'],\n",
      "        num_rows: 1065\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['age', 'id', 'group', 'tokens2'],\n",
      "        num_rows: 1253\n",
      "    })\n",
      "})\n",
      "<class 'datasets.dataset_dict.DatasetDict'>\n"
     ]
    }
   ],
   "source": [
    "print(dd.corpus_dict)\n",
    "print(type(dd.corpus_dict))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
