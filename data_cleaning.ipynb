{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook works for loading and reshaping the Eigsti and Nadig datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pylangacq\n",
      "  Downloading pylangacq-0.17.0-py3-none-any.whl (65 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.2/65.2 kB 688.2 kB/s eta 0:00:00\n",
      "Collecting tabulate[widechars]>=0.8.9\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: requests>=2.18.0 in /home/coder/.local/lib/python3.9/site-packages (from pylangacq) (2.28.1)\n",
      "Requirement already satisfied: python-dateutil>=2.0.0 in /home/coder/.local/lib/python3.9/site-packages (from pylangacq) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/coder/.local/lib/python3.9/site-packages (from python-dateutil>=2.0.0->pylangacq) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.18.0->pylangacq) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.18.0->pylangacq) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.18.0->pylangacq) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.18.0->pylangacq) (2022.6.15)\n",
      "Requirement already satisfied: wcwidth in /home/coder/.local/lib/python3.9/site-packages (from tabulate[widechars]>=0.8.9->pylangacq) (0.2.5)\n",
      "Installing collected packages: tabulate, pylangacq\n",
      "Successfully installed pylangacq-0.17.0 tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "# LOADING THE REQUIRED PACKAGES\n",
    "import os\n",
    "os.system('pip install pylangacq')\n",
    "import pylangacq \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITING A FUNCTION FOR LOADING DATA\n",
    "# This function loads each file in the directory individually, and turns it into a dataframe. Then it creates columns for age,\n",
    "# id, and group. Finally, it binds the individual dataframes together.\n",
    "\n",
    "## Accessing single files\n",
    "def dataload(datapath):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for subject in os.listdir(datapath):\n",
    "        #print(subject)\n",
    "        pylang_obj = pylangacq.read_chat(path = datapath, match = subject)\n",
    "        d = pd.DataFrame(pylang_obj.utterances())\n",
    "        d[\"age\"] = pylang_obj.ages(months=True)[0]\n",
    "        d[\"id\"] = pylang_obj.headers()[0]['PID']\n",
    "        d[\"group\"] = pylang_obj.headers()[0]['Participants']['CHI']['group']\n",
    "        df = pd.concat([df, d])\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNNING THE DATALOAD FUNCTION ON ALL FILES\n",
    "all_data = dataload(os.path.join(\"/work\", \"exam\", \"ASD_classification\", \"data\", \"corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A COLUMN WHERE EACH UTTERANCE IS A STRING\n",
    "# Accessing the word-keys in the nested dicts in the tokens column and appending them to a string in a new tokens column\n",
    "\n",
    "words = \"\"\n",
    "tokens2 = []\n",
    "\n",
    "for row in all_data['tokens']:\n",
    "    for list in row:\n",
    "        #print(list['word'])\n",
    "        words += list['word'] + \" \"\n",
    "    tokens2.append(words)\n",
    "    words = \"\"\n",
    "\n",
    "all_data['tokens2'] = tokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING THE DF\n",
    "# Dropping unnecessary columns\n",
    "all_data = all_data.drop(columns=['tokens'])\n",
    "all_data = all_data.drop(columns=['tiers'])\n",
    "all_data = all_data.drop(columns=['time_marks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TD' 'DD' 'ASD' 'TYP']\n",
      "['TD' 'ASD']\n"
     ]
    }
   ],
   "source": [
    "# We can read from the description of the datasets on talkbank.org - and see it here - that Eigstig annotated the typically\n",
    "# developing children with TD and Nadig used TYP. For consistency, we will recode all variables that are grouped TYP to TD.\n",
    "# Eigstig also has a group called DD (for developmental delay). These children have developmental delay, but not ASD. This group\n",
    "# will be filtered out.\n",
    "print(all_data['group'].unique())\n",
    "\n",
    "# Recoding TYP to TD\n",
    "all_data = all_data.replace('TYP','TD')\n",
    "\n",
    "# Dropping the rows from the DD group\n",
    "all_data = all_data[all_data.group != 'DD']\n",
    "\n",
    "# Checking the variables\n",
    "print(all_data['group'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>age</th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>tokens2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INV1</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>we've got sort of a bumblebee theme here becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INV1</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INV1</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>mmmm .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INV1</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>hm .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INV1</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>and you know what ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>MOT</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>oh that feels great .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>CHI</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>haircut .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>MOT</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>thank_you .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>CHI</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>CHI</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>now I make some my something else .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24556 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant        age                  id group  \\\n",
       "0          INV1  45.633333  11312/a-00032743-1    TD   \n",
       "1          INV1  45.633333  11312/a-00032743-1    TD   \n",
       "2          INV1  45.633333  11312/a-00032743-1    TD   \n",
       "3          INV1  45.633333  11312/a-00032743-1    TD   \n",
       "4          INV1  45.633333  11312/a-00032743-1    TD   \n",
       "..          ...        ...                 ...   ...   \n",
       "309         MOT  28.800000  11312/a-00005262-1    TD   \n",
       "310         CHI  28.800000  11312/a-00005262-1    TD   \n",
       "311         MOT  28.800000  11312/a-00005262-1    TD   \n",
       "312         CHI  28.800000  11312/a-00005262-1    TD   \n",
       "313         CHI  28.800000  11312/a-00005262-1    TD   \n",
       "\n",
       "                                               tokens2  \n",
       "0    we've got sort of a bumblebee theme here becau...  \n",
       "1                                                   .   \n",
       "2                                              mmmm .   \n",
       "3                                                hm .   \n",
       "4                                 and you know what ?   \n",
       "..                                                 ...  \n",
       "309                             oh that feels great .   \n",
       "310                                         haircut .   \n",
       "311                                       thank_you .   \n",
       "312                                                 .   \n",
       "313               now I make some my something else .   \n",
       "\n",
       "[24556 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data\n",
    "\n",
    "# Possible issue: In the Nadig data, there are a lot of rows/utterances that consist only of a punctuation, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING THE DF AS A CSV FILE\n",
    "all_data.to_csv('all_data.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INV1' 'INV2' 'MOT' 'CHI' 'FAT' 'INV' 'MOM']\n",
      "    participant        age                  id group  \\\n",
      "0          INV1  45.633333  11312/a-00032743-1    TD   \n",
      "1          INV1  45.633333  11312/a-00032743-1    TD   \n",
      "2          INV1  45.633333  11312/a-00032743-1    TD   \n",
      "3          INV1  45.633333  11312/a-00032743-1    TD   \n",
      "4          INV1  45.633333  11312/a-00032743-1    TD   \n",
      "..          ...        ...                 ...   ...   \n",
      "309         MOT  28.800000  11312/a-00005262-1    TD   \n",
      "310         CHI  28.800000  11312/a-00005262-1    TD   \n",
      "311         MOT  28.800000  11312/a-00005262-1    TD   \n",
      "312         CHI  28.800000  11312/a-00005262-1    TD   \n",
      "313         CHI  28.800000  11312/a-00005262-1    TD   \n",
      "\n",
      "                                               tokens2  \n",
      "0    we've got sort of a bumblebee theme here becau...  \n",
      "1                                                   .   \n",
      "2                                              mmmm .   \n",
      "3                                                hm .   \n",
      "4                                 and you know what ?   \n",
      "..                                                 ...  \n",
      "309                             oh that feels great .   \n",
      "310                                         haircut .   \n",
      "311                                       thank_you .   \n",
      "312                                                 .   \n",
      "313               now I make some my something else .   \n",
      "\n",
      "[24556 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_data['participant'].unique())\n",
    "\n",
    "# Dropping the rows that are not participant == CHI\n",
    "CHI_data = all_data[all_data.participant == 'CHI']\n",
    "\n",
    "CHI_data.to_csv('CHI_data.csv', index = True)\n",
    "\n",
    "print(all_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
