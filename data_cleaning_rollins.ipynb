{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook works for loading and reshaping the Eigsti and rollinssss datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pylangacq in /home/coder/.local/lib/python3.9/site-packages (0.17.0)\n",
      "Requirement already satisfied: tabulate[widechars]>=0.8.9 in /home/coder/.local/lib/python3.9/site-packages (from pylangacq) (0.9.0)\n",
      "Requirement already satisfied: requests>=2.18.0 in /home/coder/.local/lib/python3.9/site-packages (from pylangacq) (2.28.1)\n",
      "Requirement already satisfied: python-dateutil>=2.0.0 in /home/coder/.local/lib/python3.9/site-packages (from pylangacq) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/coder/.local/lib/python3.9/site-packages (from python-dateutil>=2.0.0->pylangacq) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.18.0->pylangacq) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.18.0->pylangacq) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.18.0->pylangacq) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.18.0->pylangacq) (1.26.9)\n",
      "Requirement already satisfied: wcwidth in /home/coder/.local/lib/python3.9/site-packages (from tabulate[widechars]>=0.8.9->pylangacq) (0.2.5)\n"
     ]
    }
   ],
   "source": [
    "# LOADING THE REQUIRED PACKAGES\n",
    "import os\n",
    "os.system('pip install pylangacq')\n",
    "import pylangacq \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITING A FUNCTION FOR LOADING DATA\n",
    "# This function loads each file in the directory individually, and turns it into a dataframe. Then it creates columns for age,\n",
    "# id, and group. Finally, it binds the individual dataframes together.\n",
    "\n",
    "## Accessing single files\n",
    "def dataload(datapath):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for subject in os.listdir(datapath):\n",
    "        #print(subject)\n",
    "        pylang_obj = pylangacq.read_chat(path = datapath, match = subject)\n",
    "        d = pd.DataFrame(pylang_obj.utterances())\n",
    "        d[\"age\"] = pylang_obj.ages(months=True)[0]\n",
    "        d[\"id\"] = pylang_obj.headers()[0]['PID']\n",
    "        d[\"group\"] = pylang_obj.headers()[0]['Participants']['CHI']['group']\n",
    "        df = pd.concat([df, d])\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNNING THE DATALOAD FUNCTION\n",
    "rollins = dataload(os.path.join(\"/work\", \"exam\", \"ASD_classification\", \"data\", \"rollins\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A COLUMN WHERE EACH UTTERANCE IS A STRING\n",
    "# Accessing the word-keys in the nested dicts in the tokens column and appending them to a string in a new tokens column\n",
    "\n",
    "words = \"\"\n",
    "tokens2 = []\n",
    "\n",
    "for row in rollins['tokens']:\n",
    "    for list in row:\n",
    "        #print(list['word'])\n",
    "        words += list['word'] + \" \"\n",
    "    tokens2.append(words)\n",
    "    words = \"\"\n",
    "\n",
    "rollins['tokens2'] = tokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING THE DF\n",
    "# Dropping unnecessary columns\n",
    "rollins = rollins.drop(columns=['tokens'])\n",
    "rollins = rollins.drop(columns=['tiers'])\n",
    "rollins = rollins.drop(columns=['time_marks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "# We can read from the description of the datasets on talkbank.org - and see it here - that rollins annotated the typically\n",
    "# developing children with TD and rollins used TYP. For consistency, we will recode all variables that are grouped TYP to TD.\n",
    "# rollins also has a group called DD (for developmental delay). These children have developmental delay, but not ASD. This group\n",
    "# will be filtered out.\n",
    "print(rollins['group'].unique())\n",
    "\n",
    "# Recoding TYP to TD\n",
    "rollins = rollins.replace('TYP','TD') # xxx not necessary in the rollins data\n",
    "\n",
    "# Dropping the rows from the DD group\n",
    "rollins = rollins[rollins.group != 'DD']\n",
    "\n",
    "# Checking the variables\n",
    "print(rollins['group'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>age</th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>tokens2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INV</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11312/c-00005935-1</td>\n",
       "      <td></td>\n",
       "      <td>let's CLITIC go see where the airplane is .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHI</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11312/c-00005935-1</td>\n",
       "      <td></td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INV</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11312/c-00005935-1</td>\n",
       "      <td></td>\n",
       "      <td>where do you think ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INV</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11312/c-00005935-1</td>\n",
       "      <td></td>\n",
       "      <td>is it up ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHI</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11312/c-00005935-1</td>\n",
       "      <td></td>\n",
       "      <td>up .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>CHI</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11312/c-00005939-1</td>\n",
       "      <td></td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>CHI</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11312/c-00005939-1</td>\n",
       "      <td></td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>INV</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11312/c-00005939-1</td>\n",
       "      <td></td>\n",
       "      <td>shall we put it in the cupboard ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>INV</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11312/c-00005939-1</td>\n",
       "      <td></td>\n",
       "      <td>bye bye .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>CHI</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11312/c-00005939-1</td>\n",
       "      <td></td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11020 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant   age                  id group  \\\n",
       "0           INV  36.0  11312/c-00005935-1         \n",
       "1           CHI  36.0  11312/c-00005935-1         \n",
       "2           INV  36.0  11312/c-00005935-1         \n",
       "3           INV  36.0  11312/c-00005935-1         \n",
       "4           CHI  36.0  11312/c-00005935-1         \n",
       "..          ...   ...                 ...   ...   \n",
       "552         CHI  38.0  11312/c-00005939-1         \n",
       "553         CHI  38.0  11312/c-00005939-1         \n",
       "554         INV  38.0  11312/c-00005939-1         \n",
       "555         INV  38.0  11312/c-00005939-1         \n",
       "556         CHI  38.0  11312/c-00005939-1         \n",
       "\n",
       "                                          tokens2  \n",
       "0    let's CLITIC go see where the airplane is .   \n",
       "1                                              .   \n",
       "2                         where do you think ...   \n",
       "3                                     is it up ?   \n",
       "4                                           up .   \n",
       "..                                            ...  \n",
       "552                                            .   \n",
       "553                                            .   \n",
       "554            shall we put it in the cupboard ?   \n",
       "555                                    bye bye .   \n",
       "556                                            .   \n",
       "\n",
       "[11020 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rollins\n",
    "\n",
    "# Possible issue: In the rollins data, there are a lot of rows/utterances that consist only of a punctuation, etc. xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING THE DF AS A CSV FILE\n",
    "#rollins.to_csv('df_rollins.csv', index = True) # Not necessary to save untill cleaning is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INV' 'CHI' 'INV2' 'OTH' 'UID']\n"
     ]
    }
   ],
   "source": [
    "print(rollins['participant'].unique())\n",
    "\n",
    "# Dropping the rows that are not participant == CHI\n",
    "rollins = rollins[rollins.participant == 'CHI']\n",
    "\n",
    "# Dropping the column participant (since this is always CHI now)\n",
    "rollins = rollins.drop(columns=['participant'])\n",
    "\n",
    "# Dummy coding a diagnosis column\n",
    "rollins['diagnosis'] = rollins['group'].replace(\"TD\", 0)\n",
    "rollins['diagnosis'] = rollins['diagnosis'].replace(\"ASD\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tokens(df):\n",
    "    \"\"\"This function removes weird and redundant characters and spaces\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    df['tokens2'] = df['tokens2'].str.replace('[^a-zA-Z]', ' ', regex=True)\n",
    "\n",
    "    # Single character removal\n",
    "    df['tokens2'] = df['tokens2'].str.replace(r\"\\s+[a-zA-Z]\\s+\", ' ', regex=True)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    df['tokens2'] = df['tokens2'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "    # Drop spaces created when deleting single period values\n",
    "    df = df[df.tokens2 != ' ']\n",
    "\n",
    "    return df\n",
    "\n",
    "rollins = preprocess_tokens(rollins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>tokens2</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>11312/c-00005935-1</td>\n",
       "      <td></td>\n",
       "      <td>up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36.0</td>\n",
       "      <td>11312/c-00005935-1</td>\n",
       "      <td></td>\n",
       "      <td>up here</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>36.0</td>\n",
       "      <td>11312/c-00005935-1</td>\n",
       "      <td></td>\n",
       "      <td>that CLITIC boat</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36.0</td>\n",
       "      <td>11312/c-00005935-1</td>\n",
       "      <td></td>\n",
       "      <td>airplane</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>36.0</td>\n",
       "      <td>11312/c-00005935-1</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>32.0</td>\n",
       "      <td>11312/c-00005933-1</td>\n",
       "      <td></td>\n",
       "      <td>go</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>32.0</td>\n",
       "      <td>11312/c-00005933-1</td>\n",
       "      <td></td>\n",
       "      <td>mmmm</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>32.0</td>\n",
       "      <td>11312/c-00005933-1</td>\n",
       "      <td></td>\n",
       "      <td>mmmm</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>38.0</td>\n",
       "      <td>11312/c-00005939-1</td>\n",
       "      <td></td>\n",
       "      <td>blocks</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>38.0</td>\n",
       "      <td>11312/c-00005939-1</td>\n",
       "      <td></td>\n",
       "      <td>hi</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>880 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age                  id group            tokens2 diagnosis\n",
       "4    36.0  11312/c-00005935-1                      up           \n",
       "6    36.0  11312/c-00005935-1                 up here           \n",
       "21   36.0  11312/c-00005935-1        that CLITIC boat           \n",
       "24   36.0  11312/c-00005935-1                airplane           \n",
       "30   36.0  11312/c-00005935-1                       O           \n",
       "..    ...                 ...   ...                ...       ...\n",
       "70   32.0  11312/c-00005933-1                      go           \n",
       "107  32.0  11312/c-00005933-1                    mmmm           \n",
       "109  32.0  11312/c-00005933-1                    mmmm           \n",
       "26   38.0  11312/c-00005939-1                  blocks           \n",
       "315  38.0  11312/c-00005939-1                      hi           \n",
       "\n",
       "[880 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rollins.to_csv('data/dataframes/data_rollins.csv', index = False)\n",
    "\n",
    "rollins\n",
    "\n",
    "# Tokens2 has a lot of columns that have only a \".\". I used the utterances() function to load the data, so it is\n",
    "# only the verbal utterances that are included in this dataset. If we look in the original dataset, we see that\n",
    "# the \".\"'s indicate rows where the child communicated non-verbally, e.g. by nodding, shaking their head, counting\n",
    "# on their fingers, etc. The frequecy of these in the dataset could likely also tell us something about the differ-\n",
    "# ence in language/communication between TD and ASD children, but for our purpose, we will remove these from the \n",
    "# dataset, because we are looking at verbal language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  text label\n",
      "4                  up       \n",
      "6             up here       \n",
      "21   that CLITIC boat       \n",
      "24           airplane       \n",
      "30                  O       \n",
      "..                 ...   ...\n",
      "70                 go       \n",
      "107              mmmm       \n",
      "109              mmmm       \n",
      "26             blocks       \n",
      "315                hi       \n",
      "\n",
      "[880 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Creating a short CHI dataframe with only text and label features\n",
    "rollins = rollins.drop(columns=['age', 'id', 'group']).rename(columns = {'tokens2':'text', 'diagnosis':'label'})\n",
    "print(rollins)\n",
    "rollins.to_csv('data/dataframes/data_rollins_text_label.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data to fit the LogReg and NN classifiers\n",
    "This means that the data must be in a shape of a class, which contains a tuple of three dictionaries: taining, validation, and test data. Inside each subset is a tuple with a dictionary which contains features (list) and number of rows (value). Features is a list which contains text and labels - so for our data, these would be tokens2, age, and group/diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Class with functions - not working\n",
    "# class createDatasetDict:\n",
    "\n",
    "#     def split_data(self, data):\n",
    "#         self.data = data\n",
    "\n",
    "#         # Split dataset into train, test, val (70, 15, 15)\n",
    "#         train, test = train_test_split(df, test_size=0.15)\n",
    "#         train, val = train_test_split(train, test_size=0.15)\n",
    "\n",
    "#         # Turning the split dataframes into dicts\n",
    "#         train = Dataset.from_dict(train)\n",
    "#         val = Dataset.from_dict(val)\n",
    "#         test = Dataset.from_dict(test)\n",
    "\n",
    "#         return(train, val, test)\n",
    "\n",
    "\n",
    "#     def create_dicts(self, train, val, test):\n",
    "#         corpus_dict = datasets.DatasetDict({\n",
    "#             \"train\":self.train, \n",
    "#             \"val\":self.val, \n",
    "#             \"test\":self.test\n",
    "#             })\n",
    "    \n",
    "#         return(corpus_dict)\n",
    "\n",
    "# if __name__==\"__main__\":\n",
    "#     createDatasetDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/work/exam/ASD_classification/data_cleaning_rollin.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000015vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# For the logreg and nn\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000015vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mcreateDatasetDict\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000015vscode-remote?line=2'>3</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000015vscode-remote?line=3'>4</a>\u001b[0m     \u001b[39m# Split dataset into train, test, val (70, 15, 15)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000015vscode-remote?line=4'>5</a>\u001b[0m     train, test \u001b[39m=\u001b[39m train_test_split(data, test_size\u001b[39m=\u001b[39m\u001b[39m0.15\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000015vscode-remote?line=5'>6</a>\u001b[0m     train, val \u001b[39m=\u001b[39m train_test_split(train, test_size\u001b[39m=\u001b[39m\u001b[39m0.15\u001b[39m)\n",
      "\u001b[1;32m/work/exam/ASD_classification/data_cleaning_rollin.ipynb Cell 16'\u001b[0m in \u001b[0;36mcreateDatasetDict\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000015vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mcreateDatasetDict\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000015vscode-remote?line=2'>3</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000015vscode-remote?line=3'>4</a>\u001b[0m     \u001b[39m# Split dataset into train, test, val (70, 15, 15)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000015vscode-remote?line=4'>5</a>\u001b[0m     train, test \u001b[39m=\u001b[39m train_test_split(data, test_size\u001b[39m=\u001b[39m\u001b[39m0.15\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000015vscode-remote?line=5'>6</a>\u001b[0m     train, val \u001b[39m=\u001b[39m train_test_split(train, test_size\u001b[39m=\u001b[39m\u001b[39m0.15\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000015vscode-remote?line=7'>8</a>\u001b[0m     \u001b[39m# Turning the split dataframes into dicts\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# For the logreg and nn\n",
    "class createDatasetDict:\n",
    "\n",
    "    # Split dataset into train, test, val (70, 15, 15)\n",
    "    train, test = train_test_split(data, test_size=0.15)\n",
    "    train, val = train_test_split(train, test_size=0.15)\n",
    "\n",
    "    # Turning the split dataframes into dicts\n",
    "    train = Dataset.from_dict(train)\n",
    "    val = Dataset.from_dict(val)\n",
    "    test = Dataset.from_dict(test)\n",
    "\n",
    "    corpus_dict = datasets.DatasetDict({\n",
    "        \"train\":train, \n",
    "        \"val\":val, \n",
    "        \"test\":test\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/work/exam/ASD_classification/data_dataframes_rollins_text_label.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/work/exam/ASD_classification/data_cleaning_rollin.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000016vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatasets\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000016vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n\u001b[0;32m----> <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000016vscode-remote?line=4'>5</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m/work/exam/ASD_classification/data_dataframes_rollins_text_label.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://app-326535-0.cloud.sdu.dk/work/exam/ASD_classification/data_cleaning_rollin.ipynb#ch0000016vscode-remote?line=6'>7</a>\u001b[0m dd \u001b[39m=\u001b[39m createDatasetDict()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=571'>572</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=573'>574</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=574'>575</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=576'>577</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=930'>931</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=932'>933</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=933'>934</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1213'>1214</a>\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1214'>1215</a>\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1215'>1216</a>\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1216'>1217</a>\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1217'>1218</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1218'>1219</a>\u001b[0m     f,\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1219'>1220</a>\u001b[0m     mode,\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1220'>1221</a>\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1221'>1222</a>\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1222'>1223</a>\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1223'>1224</a>\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1224'>1225</a>\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1225'>1226</a>\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1226'>1227</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1227'>1228</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1228'>1229</a>\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=780'>781</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=781'>782</a>\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=782'>783</a>\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=783'>784</a>\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=784'>785</a>\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=785'>786</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=786'>787</a>\u001b[0m             handle,\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=787'>788</a>\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=788'>789</a>\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=789'>790</a>\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=790'>791</a>\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=791'>792</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=792'>793</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=793'>794</a>\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/coder/.local/lib/python3.9/site-packages/pandas/io/common.py?line=794'>795</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/work/exam/ASD_classification/data_dataframes_rollins_text_label.csv'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "data = pd.read_csv(\"/work/exam/ASD_classification/data_dataframes_rollins_text_label.csv\")\n",
    "\n",
    "dd = createDatasetDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no . ',\n",
       " 'I to fall down . ',\n",
       " 'oh help ! ',\n",
       " 'hey , a blocks ! ',\n",
       " 'hey ! ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'yeah . ',\n",
       " \"what's this for ? \",\n",
       " 'put it on his hands and on his head . ',\n",
       " 'alright . ',\n",
       " 'yeah . ',\n",
       " 'horsie ? ',\n",
       " \"I don't know . \",\n",
       " \"it can't work anywhere . \",\n",
       " \"and you're making my face . \",\n",
       " '. ',\n",
       " 'vroom . ',\n",
       " 'touch your foot . ',\n",
       " 'his face . ',\n",
       " 'this . ',\n",
       " \"they're like in summertime . \",\n",
       " '. ',\n",
       " \"oh ‡ what's that ? \",\n",
       " 'oooh , grrrr . ',\n",
       " 'no look at me . ',\n",
       " 'good night , lion . ',\n",
       " '. ',\n",
       " 'and then , that . ',\n",
       " 'no . ',\n",
       " '. ',\n",
       " 'yeah . ',\n",
       " 'put your clothes back on . ',\n",
       " '. ',\n",
       " '. ',\n",
       " '. ',\n",
       " \"I don't know . \",\n",
       " 'yeah . ',\n",
       " 'he lost he lost lost his train . ',\n",
       " 'she drinking milk . ',\n",
       " 'tricky make these . ',\n",
       " 'numbers and letters . ',\n",
       " 'tea for two . ',\n",
       " 'I want //. ',\n",
       " 'no Daddy . ',\n",
       " 'no . ',\n",
       " 'ah . ',\n",
       " 'Mommy . ',\n",
       " 'yeah . ',\n",
       " 'yeah . ',\n",
       " 'Mama , I will glue it . ',\n",
       " '. ',\n",
       " 'mimi . ',\n",
       " 'no . ',\n",
       " 'but the giraffe came out of his cage . ',\n",
       " \"they can't get inside ! \",\n",
       " 'forklift construction . ',\n",
       " 'yeah . ',\n",
       " '. ',\n",
       " 'go to bed . ',\n",
       " 'one book . ',\n",
       " 'okay . ',\n",
       " 'hippity_hop . ',\n",
       " 'yeah . ',\n",
       " \"I'm going to find you know where it is lEæm ? \",\n",
       " 'hey I gonna jump off slide . ',\n",
       " 'hello hello ! ',\n",
       " 'are you my ʃænəɤ . ',\n",
       " 'oh no . ',\n",
       " 'Dadad Mama . ',\n",
       " 'go see Mommy . ',\n",
       " 'two . ',\n",
       " 'ah ! ',\n",
       " 'touch your . ',\n",
       " 'yeah . ',\n",
       " \"because there's the animals that are in her house . \",\n",
       " \"it's CLITIC a down . \",\n",
       " '. ',\n",
       " 'uhoh . ',\n",
       " 'a wrench . ',\n",
       " 'yeah . ',\n",
       " 'blow ! ',\n",
       " 'look . ',\n",
       " 'I wanna CLITIC move . ',\n",
       " '. ',\n",
       " 'no . ',\n",
       " 'okay . ',\n",
       " '. ',\n",
       " 'yes . ',\n",
       " 'Mommy stop singing . ',\n",
       " 'put the phone away . ',\n",
       " 'rar rar rar . ',\n",
       " 'yeah . ',\n",
       " 'take it home . ',\n",
       " 'he is . ',\n",
       " 'uhhuh . ',\n",
       " 'bath time girl ! ',\n",
       " 'that one is watching changing the tv . ',\n",
       " 'oh ‡ what is this ? ',\n",
       " 'thank you . ',\n",
       " '. ',\n",
       " 'what is this stuff ? ',\n",
       " 'I I will color this . ',\n",
       " 'right here . ',\n",
       " 'top over there . ',\n",
       " 'why ? ',\n",
       " \"it does when you put something on it moves it somewhere else what's CLITIC heavy . \",\n",
       " 'I think we so much funs doing that . ',\n",
       " 'I have toy truck . ',\n",
       " 'yeah . ',\n",
       " 'when you go this way he bumps . ',\n",
       " 'you help me ? ',\n",
       " 'no ! ',\n",
       " 'no . ',\n",
       " 'baba . ',\n",
       " 'okay . ',\n",
       " 'I want some . ',\n",
       " 'me first . ',\n",
       " \"it , it's CLITIC time to get dressed big sister ! \",\n",
       " \"it's going to make a delivery like a cookie . \",\n",
       " 'no . ',\n",
       " 'ya . ',\n",
       " 'okay . ',\n",
       " 'which . ',\n",
       " 'she kicking . ',\n",
       " 't-rex . ',\n",
       " 'no ! ',\n",
       " 'sit in this table ? ',\n",
       " 'baby . ',\n",
       " 'yeah . ',\n",
       " '. ',\n",
       " 'oh ‡ no ! ',\n",
       " 'cool , a choo choo . ',\n",
       " \"it saw apart so I could fix it what's the matter with it ? \",\n",
       " '. ',\n",
       " 'look . ',\n",
       " 'book . ',\n",
       " \"what's happening ? \",\n",
       " 'do not fall . ',\n",
       " \"it's CLITIC done . \",\n",
       " 'he can build , ah five engines , five engines in front . ',\n",
       " 'now , where is his eye ? ',\n",
       " 'yeah . ',\n",
       " \"this is a red car like Mommy's car . \",\n",
       " 'i . ',\n",
       " 'anʌ turn back on . ',\n",
       " 'and then I tried to knock it down and ! ',\n",
       " 'hide . ',\n",
       " 'touch your neck . ',\n",
       " 'yeah . ',\n",
       " 'ready . ',\n",
       " 'zz . ',\n",
       " \"no they don't . \",\n",
       " 'but they gonna CLITIC build , coming out of that . ',\n",
       " 'put her in the wagon . ',\n",
       " 'no . ',\n",
       " 'baby birthday Zaza . ',\n",
       " 'he wants too play ! ',\n",
       " 'yeah s . ',\n",
       " 'no tea . ',\n",
       " 'no . ',\n",
       " 'go see Mom ! ',\n",
       " 'no ! ',\n",
       " 'play . ',\n",
       " 'yeah baby food . ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'yeah . ',\n",
       " 'horse . ',\n",
       " 'shoulder . ',\n",
       " 'vroom . ',\n",
       " 'yes . ',\n",
       " \"I Missus lɨnɛt , I don't know . \",\n",
       " '. ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'these things they are to make me fast . ',\n",
       " \"a baby's ? \",\n",
       " '. ',\n",
       " 'what gonna CLITIC happen ? ',\n",
       " \"I'm CLITIC fine . \",\n",
       " 'oh here . ',\n",
       " 'good night moon , mountain , good night mush . ',\n",
       " 'she wants to cuddle me . ',\n",
       " '. ',\n",
       " 'going in the door . ',\n",
       " 'stamp . ',\n",
       " 'but this turns . ',\n",
       " 'yes ! ',\n",
       " 'wanna CLITIC . ',\n",
       " '. ',\n",
       " 'this is a star , a star . ',\n",
       " 'the moon is coming down . ',\n",
       " 'oy . ',\n",
       " 'I want a side one there and one there . ',\n",
       " 'babibabibibabi . ',\n",
       " 'you are . ',\n",
       " 'ah ! ',\n",
       " 'yeah . ',\n",
       " 'oh oh you all right . ',\n",
       " 'these . ',\n",
       " '. ',\n",
       " 'why there door ? ',\n",
       " 'turn the light off bɤ bɤ . ',\n",
       " 'oh no on . ',\n",
       " 'yep . ',\n",
       " \"it's a guy . \",\n",
       " 'is another block . ',\n",
       " 'hm this ? ',\n",
       " 'no . ',\n",
       " 'look əm me . ',\n",
       " 'I think . ',\n",
       " 'b . ',\n",
       " 'this work . ',\n",
       " '. ',\n",
       " 'two . ',\n",
       " 'you can do that . ',\n",
       " \"no ‡ it's ripped . \",\n",
       " 'ah . ',\n",
       " 'ugh . ',\n",
       " 'ah mamamamama . ',\n",
       " 'take this block . ',\n",
       " 'the zookeeper . ',\n",
       " 'upping . ',\n",
       " '. ',\n",
       " 'a dumptruck . ',\n",
       " '. ',\n",
       " 'na . ',\n",
       " 'on a camp . ',\n",
       " 'oy ! ',\n",
       " 'ʃeʌ . ',\n",
       " '. ',\n",
       " \"that's CLITIC why he just , she just gets a little rest by this . \",\n",
       " 'do that . ',\n",
       " 'look in her eye . ',\n",
       " '. ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'fish . ',\n",
       " \"maybe it's CLITIC time to give her a bath . \",\n",
       " 'only mom and dad use dem . ',\n",
       " 'a tractor . ',\n",
       " 'maybe some are this big . ',\n",
       " 'uhoh . ',\n",
       " 'a dog ! ',\n",
       " 'in the bus ! ',\n",
       " 'yeah . ',\n",
       " 'yeah and . ',\n",
       " 'my girl . ',\n",
       " 'nine . ',\n",
       " 'here baby having a foot . ',\n",
       " 'way up in the sky . ',\n",
       " 'turn off the light . ',\n",
       " 'no . ',\n",
       " 'Mommy do it . ',\n",
       " 'another one . ',\n",
       " \"he's doing this . \",\n",
       " 'good night little ... ',\n",
       " \"it's a bus ! \",\n",
       " 'yes . ',\n",
       " 'oh goodness . ',\n",
       " '. ',\n",
       " '. ',\n",
       " \"doesn't look like it . \",\n",
       " 'Mommy ? ',\n",
       " \"you know I think I I think he's this thing goes here and the thing dʒɛŋ hoz ah . \",\n",
       " '. ',\n",
       " '. ',\n",
       " 'dɨ . ',\n",
       " 'two three two /. ',\n",
       " 'yes . ',\n",
       " 'go Mommy . ',\n",
       " 'mamamamamamamamama . ',\n",
       " 'crash . ',\n",
       " 'I I need a to it . ',\n",
       " 'Mommy busy Mommy . ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'hi Hallil at the daycare okay . ',\n",
       " 'no ! ',\n",
       " \"that's the letter in my name too . \",\n",
       " 'right over there . ',\n",
       " 'so much . ',\n",
       " 'why . ',\n",
       " 'the measure . ',\n",
       " 'how does this turn on ? ',\n",
       " 'goes round and round and round . ',\n",
       " 'Mommy ! ',\n",
       " 'do you ? ',\n",
       " 'we /. ',\n",
       " 'on there . ',\n",
       " 'yeah . ',\n",
       " 'lookit the beautiful , they are shape . ',\n",
       " 'lookit , she can turn around . ',\n",
       " 'yeah . ',\n",
       " 'ʌf ʌf ʌf . ',\n",
       " \"it's a beetle . \",\n",
       " '. ',\n",
       " 'this a key . ',\n",
       " '. ',\n",
       " 'this is a mommy . ',\n",
       " 'yeah . ',\n",
       " '. ',\n",
       " \"that's CLITIC another baby . \",\n",
       " '. ',\n",
       " 'turn it on . ',\n",
       " 'three . ',\n",
       " 'ʒir . ',\n",
       " '. ',\n",
       " 'yes . ',\n",
       " 'there we go . ',\n",
       " 'night . ',\n",
       " 'nʌrʌ dogs ! ',\n",
       " \"it's CLITIC not working . \",\n",
       " 'yes . ',\n",
       " 'look . ',\n",
       " 'baby doctor . ',\n",
       " 'more . ',\n",
       " 'some dese . ',\n",
       " 'no . ',\n",
       " 'mountain , lake , sunlight . ',\n",
       " '. ',\n",
       " 'eʔdʒʌk . ',\n",
       " 'yes . ',\n",
       " 'crash . ',\n",
       " 'put them in the put them in the door . ',\n",
       " 'dɔtigɤdi . ',\n",
       " 'why ? ',\n",
       " \"where's Mommy ? \",\n",
       " 'look . ',\n",
       " 'no . ',\n",
       " \"I don't know . \",\n",
       " 'yeah . ',\n",
       " \"I don't know . \",\n",
       " 'betæte . ',\n",
       " 'no ‡ I want a car . ',\n",
       " 'yeah . ',\n",
       " \"it's Goldilocks . \",\n",
       " '. ',\n",
       " 'this one . ',\n",
       " 'them are mango orange . ',\n",
       " \"I don't know . \",\n",
       " '. ',\n",
       " 'no . ',\n",
       " 'g . ',\n",
       " 'whee . ',\n",
       " \"I don't know . \",\n",
       " 'ah , can I try ? ',\n",
       " 'əo . ',\n",
       " 'yeah ! ',\n",
       " 'shelf . ',\n",
       " 'good night zoo . ',\n",
       " 'you know that a , that a crane breaks ? ',\n",
       " 'put the sticker right here under the baclaun . ',\n",
       " '. ',\n",
       " 'no . ',\n",
       " 'those three , box top . ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'there was a telephone , and a red balloon , and a picture of ... ',\n",
       " 'hey ! ',\n",
       " 'why you want , hey hey hey . ',\n",
       " 'he thinks about what is another long train this another long train this is another long train like this another long , long train . ',\n",
       " 'wind blows the cradle will rock . ',\n",
       " 'about cars . ',\n",
       " '. ',\n",
       " 'to the fairy land . ',\n",
       " 'uhoh . ',\n",
       " 'more . ',\n",
       " '. ',\n",
       " 'no ! ',\n",
       " 'haeboɤboɤ m haeboɤboɤ o and p ! ',\n",
       " 'I see a car . ',\n",
       " \"it's there ! \",\n",
       " \"I don't want to . \",\n",
       " '. ',\n",
       " 'no . ',\n",
       " \"it's CLITIC a , it's CLITIC my , it's CLITIC a phone . \",\n",
       " \"she's still five . \",\n",
       " 'he looks like like giddybom . ',\n",
       " 'and daddy . ',\n",
       " 'wires . ',\n",
       " 'it just you . ',\n",
       " '. ',\n",
       " 'yep . ',\n",
       " 'the day we gimme my surprise . ',\n",
       " 'dʒurʌ . ',\n",
       " \"can't go on there . \",\n",
       " 'nʌ locking the door . ',\n",
       " \"we're kind of running away now . \",\n",
       " \"it's David . \",\n",
       " '. ',\n",
       " 'I needta CLITIC . ',\n",
       " 'good night , good night , good night , good night , good night , good night good night . ',\n",
       " \"you turn on the light and he's upside-down . \",\n",
       " 'Big_Bird . ',\n",
       " 'getting some peeps and some candy . ',\n",
       " 'no . ',\n",
       " \"where's that ? \",\n",
       " '. ',\n",
       " '. ',\n",
       " 'there . ',\n",
       " \"ugh I'm stuck . \",\n",
       " 'what does this do ? ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'and , where the papa Bear ? ',\n",
       " 'nope . ',\n",
       " '. ',\n",
       " 'oh my bʌk here . ',\n",
       " 'dolphin play in the back owd . ',\n",
       " 'no ! ',\n",
       " 'this color , that color , this color , all the colors are silly to throw . ',\n",
       " '. ',\n",
       " 'I will . ',\n",
       " \"elephant's coming out too . \",\n",
       " \"I , I'm CLITIC the mommy . \",\n",
       " 'look . ',\n",
       " 'no . ',\n",
       " 'he has a map in in his hat . ',\n",
       " 'yeah have them at school . ',\n",
       " 'Wegmans . ',\n",
       " 'baby . ',\n",
       " \"it's a car . \",\n",
       " 'bat . ',\n",
       " 'but I wanna CLITIC take this . ',\n",
       " 'not coming out . ',\n",
       " 'bu bauz ? ',\n",
       " 'easy . ',\n",
       " 'in the airplane . ',\n",
       " 'no . ',\n",
       " \"we're having lot's of fun , aren't we ? \",\n",
       " 'beep . ',\n",
       " \"that's CLITIC a fork ! \",\n",
       " 'yes . ',\n",
       " 'no no not yet . ',\n",
       " '. ',\n",
       " 'set . ',\n",
       " 'no . ',\n",
       " 'no . ',\n",
       " 'hi ! ',\n",
       " 'now can I have some . ',\n",
       " 'there it is . ',\n",
       " \"yeah , it's a heavy train . \",\n",
       " 'nijau ! ',\n",
       " 'what is it ? ',\n",
       " 'put her shirt , her pajama down . ',\n",
       " 'what are you get to build . ',\n",
       " 'and now , lookit him . ',\n",
       " 'no ! ',\n",
       " 'yeah . ',\n",
       " '. ',\n",
       " 'yeah . ',\n",
       " 'in the pickup truck ! ',\n",
       " '. ',\n",
       " 'no . ',\n",
       " \"hey , it doesn't fit me very well . \",\n",
       " 'more . ',\n",
       " '. ',\n",
       " 'and , and he really thinks about another long train . ',\n",
       " 'yeah . ',\n",
       " 'saw . ',\n",
       " 'yeah ? ',\n",
       " 'that she keeps it in there . ',\n",
       " 'car . ',\n",
       " \"she's CLITIC very three . \",\n",
       " 'good night gorilla . ',\n",
       " 'and dump it all . ',\n",
       " 'a fruit . ',\n",
       " \"he's a he . \",\n",
       " 'pet ni . ',\n",
       " '. ',\n",
       " 'yeah . ',\n",
       " 'we play one of those . ',\n",
       " 'ew Zozo . ',\n",
       " 'hello . ',\n",
       " 'yep . ',\n",
       " \"what's inside ? \",\n",
       " 'why ? ',\n",
       " '. ',\n",
       " \"I don't CLITIC wanna CLITIC ! \",\n",
       " 'no . ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'he has blood on his head . ',\n",
       " 'they jump over it . ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'yeah . ',\n",
       " 'huh ? ',\n",
       " 'come ! ',\n",
       " 'why winking Mommy ? ',\n",
       " 'milk . ',\n",
       " 'look , a traffic light . ',\n",
       " 'to make a tower . ',\n",
       " 'okay . ',\n",
       " 'mouse and monkey . ',\n",
       " 'put all these stuff away . ',\n",
       " 'look ! ',\n",
       " 'ah . ',\n",
       " '. ',\n",
       " 'this is my hat , for the tools . ',\n",
       " 'too babyish ! ',\n",
       " \"I'm going be four inches . \",\n",
       " 'big one . ',\n",
       " 'yeah tricky . ',\n",
       " 'like that song . ',\n",
       " 'what ? ',\n",
       " 'good_night gorilla . ',\n",
       " 'he has eyes and he and this . ',\n",
       " 'yes , no . ',\n",
       " '. ',\n",
       " 'why ? ',\n",
       " '. ',\n",
       " 'yes , see , . ',\n",
       " 'boua . ',\n",
       " 'is there something in here ? ',\n",
       " 'go . ',\n",
       " 'I go play with Daddy . ',\n",
       " \"can't get it . \",\n",
       " '. ',\n",
       " 'no . ',\n",
       " '. ',\n",
       " 'I kick it . ',\n",
       " 'and baby have a booboo too . ',\n",
       " 'you broke a ! ',\n",
       " 'yeah ! ',\n",
       " '. ',\n",
       " \"what's happening ? \",\n",
       " 'rooster . ',\n",
       " \"no thanks sugar's CLITIC not good for me . \",\n",
       " 'no . ',\n",
       " 'vroom vroom . ',\n",
       " 'bye . ',\n",
       " 'ah . ',\n",
       " 'oh ‡ I found a jellybean . ',\n",
       " 'over here . ',\n",
       " 'yup . ',\n",
       " 'I wanna CLITIC put it in . ',\n",
       " 'a streak of silver . ',\n",
       " 'yeah . ',\n",
       " 'and and a saw . ',\n",
       " 'hai u kwe hey take it out . ',\n",
       " '. ',\n",
       " 'yeah . ',\n",
       " '. ',\n",
       " 'no . ',\n",
       " \"what's this ? \",\n",
       " '. ',\n",
       " 'so who how many foods do they eat ? ',\n",
       " 'yeah . ',\n",
       " 'oh ! ',\n",
       " '. ',\n",
       " \"that's where it goes , it goes here . \",\n",
       " 'ðo //. ',\n",
       " 'good night lion . ',\n",
       " 'Dorothy . ',\n",
       " \"look he's CLITIC eating a lot food . \",\n",
       " 'dududu . ',\n",
       " 'yeah ! ',\n",
       " '! ',\n",
       " 'no no . ',\n",
       " 'and /. ',\n",
       " 'what is here ? ',\n",
       " 'this is the //. ',\n",
       " 'yeah . ',\n",
       " \"he unlock the cage now so he's pulling them and pulling them and hga . \",\n",
       " 'yes . ',\n",
       " 'he can go on my legs . ',\n",
       " 'so you put it next to the other black one . ',\n",
       " \"I'm CLITIC giving it to her . \",\n",
       " 'I want some milk . ',\n",
       " 'my hair gets in the way . ',\n",
       " 'hey . ',\n",
       " 'bzz . ',\n",
       " 'horse ? ',\n",
       " '. ',\n",
       " 'bzz . ',\n",
       " '! ',\n",
       " \"it's a flying man though . \",\n",
       " 'who are you ! ',\n",
       " 'yeah . ',\n",
       " 'here it comes . ',\n",
       " 'wrɨ good . ',\n",
       " 'cheers . ',\n",
       " '. ',\n",
       " 'no . ',\n",
       " 'eyes . ',\n",
       " '. ',\n",
       " \"I think so it , no it's a hammer . \",\n",
       " 'nʌ ʌh . ',\n",
       " 'nau sai bed . ',\n",
       " \"but it's not a saw . \",\n",
       " 'x x . ',\n",
       " \"I don't know . \",\n",
       " 'I can draw . ',\n",
       " 'yeah . ',\n",
       " 'what is this ? ',\n",
       " 'oh ‡ vroom . ',\n",
       " 'yeah . ',\n",
       " 'no . ',\n",
       " 'blow ! ',\n",
       " 'wow . ',\n",
       " 'oh yeah . ',\n",
       " \"I don't know . \",\n",
       " 'no . ',\n",
       " 'cover ears please . ',\n",
       " 'good night moon . ',\n",
       " 'I wanna CLITIC . ',\n",
       " \"that's CLITIC too hot ! \",\n",
       " 'hey where //. ',\n",
       " 'oh no , my truck crashed ! ',\n",
       " 'and there a hammer . ',\n",
       " 'this fall down ? ',\n",
       " 'Oscar_The_Grouch just just likes yucky things like /. ',\n",
       " '. ',\n",
       " 'me . ',\n",
       " 'no . ',\n",
       " 'yeah . ',\n",
       " 'k ai tʃ yellow . ',\n",
       " 'look how big she got . ',\n",
       " 'uhhuh . ',\n",
       " \"somebody's scared swimming . \",\n",
       " 'yellow . ',\n",
       " 'dudududu . ',\n",
       " 'a monkey ! ',\n",
       " 'wow . ',\n",
       " 'to see the Seabreeze . ',\n",
       " 'not here . ',\n",
       " 'yes . ',\n",
       " 'dinosaur . ',\n",
       " 'four . ',\n",
       " 'but I /. ',\n",
       " 'tɨkʌ ʌ back on . ',\n",
       " '. ',\n",
       " 'I have blocks too . ',\n",
       " \"I'm going fast right now ! \",\n",
       " 'fall down a minute . ',\n",
       " 'yes , . ',\n",
       " \"someone's sitting my chair . \",\n",
       " 'no . ',\n",
       " 'yes . ',\n",
       " 'and more , more , more milk ? ',\n",
       " \"but they're CLITIC building a building . \",\n",
       " 'tea ? ',\n",
       " '. ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'hm , wow . ',\n",
       " '. ',\n",
       " 'ah ! ',\n",
       " 'I had that one before . ',\n",
       " 'yes . ',\n",
       " 'Mommy . ',\n",
       " 'kungfu . ',\n",
       " 'she make a mess . ',\n",
       " 'naked ! ',\n",
       " 'no . ',\n",
       " 'I think ... ',\n",
       " \"they're going inside his house . \",\n",
       " 'my here . ',\n",
       " 'they have paiyews too . ',\n",
       " \"oh they're getting them ! \",\n",
       " 'go inside there and cut the knife . ',\n",
       " 'changing color , sorry machine , sorry , back in space . ',\n",
       " \"that's when I'm five . \",\n",
       " 'yeah and think about it and think about it dumping and think about what he can make . ',\n",
       " 'I never went to swimming class . ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'no going go outside . ',\n",
       " 'keys . ',\n",
       " '. ',\n",
       " 'yes . ',\n",
       " 'bye hologram ! ',\n",
       " 'this car go , boom ! ',\n",
       " 'juice ? ',\n",
       " '. ',\n",
       " 'carrot cake and you can have my you can have my cake . ',\n",
       " '. ',\n",
       " 'get my hair out the way . ',\n",
       " '. ',\n",
       " \"that's not a wheel , it's only a little wheel . \",\n",
       " 'wow . ',\n",
       " 'hey ! ',\n",
       " 'mine too . ',\n",
       " 'go to bed . ',\n",
       " 'hanging on the things right here . ',\n",
       " \"it's a car ! \",\n",
       " 'hi Daddy . ',\n",
       " 'uhoh ! ',\n",
       " 'eeee . ',\n",
       " 'good night , lion . ',\n",
       " 'he I think he wants to go to the car store too . ',\n",
       " \"it's Sarah . \",\n",
       " 'and kitty cats . ',\n",
       " '. ',\n",
       " 'whoa ! ',\n",
       " \"there's CLITIC toys in there ? \",\n",
       " 'okay ‡ ugh , I see it . ',\n",
       " 'climbing back in . ',\n",
       " 'and I think it hurts . ',\n",
       " 'no put it in there . ',\n",
       " 'no . ',\n",
       " 'yeah . ',\n",
       " \"yeah because it's very hard . \",\n",
       " 'ah ! ',\n",
       " 'no . ',\n",
       " 'Big Bird . ',\n",
       " 'red and black . ',\n",
       " 'æh hæh haiʌi . ',\n",
       " 'mm . ',\n",
       " \"I'll protect you , don't worry . \",\n",
       " 'little daycare . ',\n",
       " 'see . ',\n",
       " '. ',\n",
       " \"he's gonna eat it . \",\n",
       " 'bubbles . ',\n",
       " \"what's this say , seven , seven , seven . \",\n",
       " 'okay bye . ',\n",
       " \"Aunt Sharon's house . \",\n",
       " 'yeah ? ',\n",
       " 'there , no . ',\n",
       " 'like that . ',\n",
       " 'arf . ',\n",
       " 'no tea . ',\n",
       " 'yeah . ',\n",
       " \"oh you want some have some cheerios that's CLITIC a have no the baby . \",\n",
       " 'I want some more ! ',\n",
       " 'this one . ',\n",
       " 'can you help me ? ',\n",
       " 'yeah . ',\n",
       " 'see ? ',\n",
       " 'maybe we could put the Playdoh here . ',\n",
       " 'light on . ',\n",
       " \"that's CLITIC a banyu . \",\n",
       " \"he's still like a pig . \",\n",
       " 'carrots ! ',\n",
       " 'what is this stuff ? ',\n",
       " '. ',\n",
       " 'well , is it cute ? ',\n",
       " 'and me . ',\n",
       " 'uhoh ! ',\n",
       " \"oh ‡ here's the bus ! \",\n",
       " \"it's CLITIC a . \",\n",
       " 'oh this ! ',\n",
       " 'pa pabier . ',\n",
       " 'ʌdʌ thirsty . ',\n",
       " \"let's play with my toy . \",\n",
       " '. ',\n",
       " 'he was tɛpɨng . ',\n",
       " 'ah , ah I have cake . ',\n",
       " '. ',\n",
       " 'why her eye broken . ',\n",
       " 'puzzle cake no more . ',\n",
       " 'this is a be a , a station . ',\n",
       " 'I needta CLITIC put this on the chair . ',\n",
       " 'this makes the same construction . ',\n",
       " 'no . ',\n",
       " '. ',\n",
       " 'one fish two fish three fish three four fish five fish . ',\n",
       " '. ',\n",
       " 'wait I need go move backwards . ',\n",
       " \"I'm CLITIC cleaning up . \",\n",
       " 'hm . ',\n",
       " 'mekə he yeah . ',\n",
       " 'stamp ! ',\n",
       " 'rr . ',\n",
       " \"what's CLITIC in your cup Hagrid ? \",\n",
       " \"I don't know . \",\n",
       " 'well , we got trucks at home and a hammer . ',\n",
       " \"it's too cold ! \",\n",
       " 'yeah . ',\n",
       " 'why Mommy ? ',\n",
       " 'baby . ',\n",
       " 'baby have a booboo . ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'a sitting down move . ',\n",
       " '. ',\n",
       " 'oh , oh for , oh lemme CLITIC milk ? ',\n",
       " \"he's in trouble . \",\n",
       " 'no . ',\n",
       " 'tuesday . ',\n",
       " \"now , what's balu . \",\n",
       " 'yeah . ',\n",
       " 'na . ',\n",
       " '. ',\n",
       " 'oh wait . ',\n",
       " 'no . ',\n",
       " 'and the vinɤs and clean is up the air . ',\n",
       " 'oh no . ',\n",
       " '. ',\n",
       " \"there's something a problem with it . \",\n",
       " \"I'm CLITIC rubbing his hair . \",\n",
       " \"you know that boy's doing ? \",\n",
       " '. ',\n",
       " 'I dunno . ',\n",
       " \"the but the gorilla's still out of his cave . \",\n",
       " 'so somebody stepped on the ice cream cone . ',\n",
       " 'no . ',\n",
       " 'a balloon ? ',\n",
       " 'maybe tomorrow . ',\n",
       " 'who ? ',\n",
       " 'I peek . ',\n",
       " 'they going to call Daddy and ... ',\n",
       " 'crashed right over here . ',\n",
       " 'happy haircut . ',\n",
       " \"they're sleeping . \",\n",
       " 'uhoh . ',\n",
       " \"I'm CLITIC drive . \",\n",
       " 'ɔ mi si . ',\n",
       " 'no it . ',\n",
       " 'oh no baby . ',\n",
       " 'her hat . ',\n",
       " 'I find ... ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'dru aiit . ',\n",
       " \"I don't know hɔɨŋ nɛwe ɨz . \",\n",
       " 'good night . ',\n",
       " 'wrench . ',\n",
       " 'yeah . ',\n",
       " '. ',\n",
       " 'he needs it . ',\n",
       " 'no . ',\n",
       " 'wow , they all went into the bus . ',\n",
       " \"I don't waik you do that . \",\n",
       " 'who are you ? ',\n",
       " 'sometimes . ',\n",
       " 'got one being born and one nothing else . ',\n",
       " \"I'm ready . \",\n",
       " '. ',\n",
       " 'frogs ! ',\n",
       " 'okay . ',\n",
       " '. ',\n",
       " 'no . ',\n",
       " 'cars and trucks and things . ',\n",
       " 'okay . ',\n",
       " 'I can go in my home . ',\n",
       " 'can you help me . ',\n",
       " \"let's CLITIC make ... \",\n",
       " 'there he is . ',\n",
       " 'no ! ',\n",
       " 'these ones are not frozen . ',\n",
       " 'see ? ',\n",
       " 'on ice . ',\n",
       " 'need just right . ',\n",
       " \"I don't CLITIC wanna CLITIC clean up . \",\n",
       " 'closed and open . ',\n",
       " 'no . ',\n",
       " 'the pigs , I love pigs . ',\n",
       " \"on Mommy's knee and on Mommy's glasses . \",\n",
       " \"ooh , that's like me . \",\n",
       " 'this is a funny thing . ',\n",
       " '. ',\n",
       " 'I want to stamp . ',\n",
       " 'those all the things I need . ',\n",
       " 'cow . ',\n",
       " 'yeah . ',\n",
       " 'here you can have more blueberry cake . ',\n",
       " 'Rachel cup have a cup cup of tea . ',\n",
       " 'four . ',\n",
       " 'it flying ! ',\n",
       " 'mhm . ',\n",
       " 'we being in Rochester . ',\n",
       " 'it break . ',\n",
       " \"I don't know , it's kinda like you are having some much fun . \",\n",
       " '. ',\n",
       " 'lookit , she has a mad face on the other cheek . ',\n",
       " 'good night gorilla . ',\n",
       " '. ',\n",
       " 'yeah . ',\n",
       " \"lookit him , he's gonna sit . \",\n",
       " 'yes . ',\n",
       " \"it's a toy . \",\n",
       " 'got it . ',\n",
       " 'one . ',\n",
       " 'one . ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'you wanna get this up in sky ? ',\n",
       " \"I don't think I can call him something . \",\n",
       " 'yeah . ',\n",
       " 'wait maybe we can use these , these squares . ',\n",
       " 'just one cat . ',\n",
       " 'mm yeah . ',\n",
       " 'yeah . ',\n",
       " 'the mouse . ',\n",
       " 'I see a train . ',\n",
       " 'no . ',\n",
       " 'mm . ',\n",
       " 'the lion . ',\n",
       " '. ',\n",
       " 'in the mirror . ',\n",
       " 'got his keys . ',\n",
       " 'ooh , mans are ... ',\n",
       " \"her hat's does come off ! \",\n",
       " \"hey , at the doctor's the girls have this . \",\n",
       " '. ',\n",
       " \"it's a ball . \",\n",
       " \"because we're CLITIC hafta CLITIC go ? \",\n",
       " 'sorry . ',\n",
       " 'yes . ',\n",
       " \"I'm walking the blocks . \",\n",
       " 'what now what are you doing ? ',\n",
       " 'another truck ? ',\n",
       " 'blocks , blocks , blocks , blocks , blocks . ',\n",
       " 'get that key out . ',\n",
       " 'clean up . ',\n",
       " \"hm I don't CLITIC get . \",\n",
       " '. ',\n",
       " 'in their bedroom . ',\n",
       " \"this is that's a wing . \",\n",
       " 'okay , I will . ',\n",
       " \"I don't know . \",\n",
       " \"they're inside of our house . \",\n",
       " 'yeah . ',\n",
       " 'boing . ',\n",
       " 'wow . ',\n",
       " \"I don't know . \",\n",
       " '. ',\n",
       " 'I going on score . ',\n",
       " 'yeah . ',\n",
       " 'I dunno , looks like letters and numbers . ',\n",
       " 'no . ',\n",
       " 'yummy ! ',\n",
       " 'yeah . ',\n",
       " 'set fire . ',\n",
       " '. ',\n",
       " 'the firetruck ! ',\n",
       " 'and come and going to ... ',\n",
       " '. ',\n",
       " 'no . ',\n",
       " '. ',\n",
       " \"can I see what's in there ? \",\n",
       " 'see ? ',\n",
       " 'almost ready bababababa bus . ',\n",
       " \"no ‡ it's a a , b , c . \",\n",
       " 'can you make mine ? ',\n",
       " \"he's not fitting in the roof . \",\n",
       " 'no . ',\n",
       " 'bzz bzz bzz bzz bzz bzz . ',\n",
       " \"I'm CLITIC okay . \",\n",
       " \"it's little bunny with big fat tail . \",\n",
       " '. ',\n",
       " '. ',\n",
       " 'no ! ',\n",
       " 'mm . ',\n",
       " 'ah /. ',\n",
       " 'grrr ! ',\n",
       " 'yes . ',\n",
       " 'no . ',\n",
       " 'I barfed . ',\n",
       " 'this is a medicine ? ',\n",
       " \"dogs don't live in water . \",\n",
       " '. ',\n",
       " 'gopher . ',\n",
       " '. ',\n",
       " \"it's getting cold here . \",\n",
       " 'yes . ',\n",
       " 'small house . ',\n",
       " 'let me think about it . ',\n",
       " 'no . ',\n",
       " 'too . ',\n",
       " 'I wanna CLITIC build and this and this and /. ',\n",
       " \"I don't have a trunk . \",\n",
       " 'rrr . ',\n",
       " 'horse . ',\n",
       " 'this not any more . ',\n",
       " 'yes . ',\n",
       " 'not here . ',\n",
       " 'rr . ',\n",
       " 'one , one , two , three . ',\n",
       " 'hm . ',\n",
       " 'in the house they go . ',\n",
       " 'uhoh . ',\n",
       " 'yeah . ',\n",
       " 'yeah . ',\n",
       " 'stop it , Brian , ouch , ouch . ',\n",
       " 'I wanna CLITIC find another thing . ',\n",
       " \"it's a sticker . \",\n",
       " 'it was the pu ? ',\n",
       " 'hɛ hɛ hɛ . ',\n",
       " 'no . ',\n",
       " 'no . ',\n",
       " 'yeah . ',\n",
       " 'bouge monster truck . ',\n",
       " '. ',\n",
       " 'then can I eat it ? ',\n",
       " 'wait , how about you take all of the things out of the puzzles , and then , hey //. ',\n",
       " 'like that ? ',\n",
       " 'with Mommy . ',\n",
       " 'ah . ',\n",
       " '. ',\n",
       " 'yeah . ',\n",
       " 'we just throw them around . ',\n",
       " '. ',\n",
       " '. ',\n",
       " 'voom . ',\n",
       " ...]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(dd.corpus_dict)\n",
    "# print(type(dd.corpus_dict))\n",
    "dd.corpus_dict['train']['tokens2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['TD', 'ASD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the BERT\n",
    "class createDatasetDict:\n",
    "\n",
    "    model_checkpoint = \"distilbert-base-uncased\"\n",
    "\n",
    "    # Split dataset into train, test, val (70, 15, 15)\n",
    "    train, test = train_test_split(data, test_size=0.15)\n",
    "    train, val = train_test_split(train, test_size=0.15)\n",
    "\n",
    "    # Convert to numpy\n",
    "    x_train = train['tokens2'].values[train_idx]\n",
    "    x_test = test['tokens2'].values[test_idx]\n",
    "    x_val = val['tokens2'].values[val_idx]\n",
    "\n",
    "    # Turning the split dataframes into dicts\n",
    "    x_train = Dataset.from_dict(x_train)\n",
    "    x_val = Dataset.from_dict(x_val)\n",
    "    x_test = Dataset.from_dict(x_test)\n",
    "\n",
    "    # Create tokenizer from pretrained model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "    corpus_dict = datasets.DatasetDict({\n",
    "        \"train\": [train, x_train], \n",
    "        \"val\": [val, x_val], \n",
    "        \"test\": [test, x_test]\n",
    "        })\n",
    "\n",
    "\n",
    "train_tok = tokenizer(list(x_train), truncation=True, padding=True, max_length=20)\n",
    "val_tok = tokenizer(list(x_val), truncation=True, padding=True, max_length=20)\n",
    "test_tok = tokenizer(list(x_test),  truncation=True, padding=True, max_length=20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
