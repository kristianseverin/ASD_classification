{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/kristian/Documents/Skole/7. semester/NLP/Exam/ASD_classification/CHI_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tokens(df):\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    df['tokens2'] = df['tokens2'].str.replace('[^a-zA-Z]', ' ', regex=True)\n",
    "\n",
    "    # Single character removal\n",
    "    df['tokens2'] = df['tokens2'].str.replace(r\"\\s+[a-zA-Z]\\s+\", ' ', regex=True)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    df['tokens2'] = df['tokens2'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "    # Drop spaces created when deleting single period values\n",
    "    df = df[df.tokens2 != ' ']\n",
    "\n",
    "    return df\n",
    "\n",
    "# use function on data frame\n",
    "data = preprocess_tokens(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>participant</th>\n",
       "      <th>age</th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>tokens2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>110</td>\n",
       "      <td>CHI</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>cow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>135</td>\n",
       "      <td>CHI</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>141</td>\n",
       "      <td>CHI</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>bandaid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>147</td>\n",
       "      <td>CHI</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>ow ipep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>162</td>\n",
       "      <td>CHI</td>\n",
       "      <td>45.633333</td>\n",
       "      <td>11312/a-00032743-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>brush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8347</th>\n",
       "      <td>300</td>\n",
       "      <td>CHI</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>love you haircut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8348</th>\n",
       "      <td>304</td>\n",
       "      <td>CHI</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>no Mama no not just ponytail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8349</th>\n",
       "      <td>306</td>\n",
       "      <td>CHI</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>I just your hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8350</th>\n",
       "      <td>310</td>\n",
       "      <td>CHI</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>haircut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8352</th>\n",
       "      <td>313</td>\n",
       "      <td>CHI</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>11312/a-00005262-1</td>\n",
       "      <td>TD</td>\n",
       "      <td>now make some my something else</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7120 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 participant        age                  id group  \\\n",
       "6            110         CHI  45.633333  11312/a-00032743-1    TD   \n",
       "12           135         CHI  45.633333  11312/a-00032743-1    TD   \n",
       "13           141         CHI  45.633333  11312/a-00032743-1    TD   \n",
       "14           147         CHI  45.633333  11312/a-00032743-1    TD   \n",
       "17           162         CHI  45.633333  11312/a-00032743-1    TD   \n",
       "...          ...         ...        ...                 ...   ...   \n",
       "8347         300         CHI  28.800000  11312/a-00005262-1    TD   \n",
       "8348         304         CHI  28.800000  11312/a-00005262-1    TD   \n",
       "8349         306         CHI  28.800000  11312/a-00005262-1    TD   \n",
       "8350         310         CHI  28.800000  11312/a-00005262-1    TD   \n",
       "8352         313         CHI  28.800000  11312/a-00005262-1    TD   \n",
       "\n",
       "                               tokens2  \n",
       "6                                 cow   \n",
       "12                               tree   \n",
       "13                            bandaid   \n",
       "14                            ow ipep   \n",
       "17                              brush   \n",
       "...                                ...  \n",
       "8347                 love you haircut   \n",
       "8348     no Mama no not just ponytail   \n",
       "8349                 I just your hair   \n",
       "8350                          haircut   \n",
       "8352  now make some my something else   \n",
       "\n",
       "[7120 rows x 6 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['TD', 'ASD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, test, val (80, 10, 10)\n",
    "train, test = train_test_split(data, test_size=0.1)\n",
    "train, val = train_test_split(train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new index with the same length as the splits\n",
    "train_idx = [i for i in range(len(train.index))]\n",
    "test_idx = [i for i in range(len(test.index))]\n",
    "val_idx = [i for i in range(len(val.index))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "x_train = train['tokens2'].values[train_idx]\n",
    "x_test = test['tokens2'].values[test_idx]\n",
    "x_val = val['tokens2'].values[val_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y splits to numpy\n",
    "y_train = train['group'].values[train_idx]\n",
    "y_test = test['group'].values[test_idx]\n",
    "y_val = val['group'].values[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yeah ', 'yes ', 'pink pink telephone ki ', ..., 'on plate ',\n",
       "       'Goldilocks ', 'swim and play Ring Around The Rosy '], dtype=object)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer from pretrained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Tokenize datasets\n",
    "train_tok = tokenizer(list(x_train), truncation=True, padding=True, max_length=20)\n",
    "val_tok = tokenizer(list(x_val), truncation=True, padding=True, max_length=20)\n",
    "test_tok = tokenizer(list(x_test),  truncation=True, padding=True, max_length=20)\n",
    "\n",
    "# label\n",
    "#train_tok[\"labels\"] = train_tok[\"input_ids\"].copy()\n",
    "#val_tok[\"labels\"] = val_tok[\"input_ids\"].copy()\n",
    "#test_tok[\"labels\"] = test_tok[\"input_ids\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make datasets\n",
    "train_dataset = Dataset.from_dict(train_tok)\n",
    "\n",
    "val_dataset = Dataset.from_dict(val_tok)\n",
    "\n",
    "test_dataset = Dataset.from_dict(test_tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 5762\n",
       "})"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad5abe4c0514a27ae6d21949f24c459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
