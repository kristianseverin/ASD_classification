{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading modules \n",
    "!pip install simpletransformers  # force install simpletrransformers in colab-environment\n",
    "\n",
    "# Importing modules\n",
    "import pandas as pd\n",
    "import simpletransformers\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import torch\n",
    "from torch.nn.modules.activation import Threshold\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import wandb\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount colab to Google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "data = pd.read_csv('/content/drive/MyDrive/NLP hva så/ASD_classification/data/dataframes/data_eigstig_text_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter sweep-values\n",
    "sweep_configuration = {\n",
    "    'method': 'random',\n",
    "    'metric': {'name': 'train_loss', 'goal': 'minimize'},\n",
    "    'parameters': \n",
    "    {\n",
    "        'batch_size': {'values': [8,16, 32, 64]},\n",
    "        'epochs': {'values': [5, 20, 50, 100]},\n",
    "        'lr': {'max': 0.1, 'min': 0.0001}\n",
    "     }\n",
    "}\n",
    "\n",
    "# refer sweep to wandb project\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project='Parameter Sweep5')\n",
    "\n",
    "# split data into train and test\n",
    "train, test = train_test_split(data, test_size=0.1)\n",
    "\n",
    "# train data to use for training and validation (splitting later on)\n",
    "train_data = train\n",
    "eval_data =  test\n",
    "\n",
    "# Define model arguments\n",
    "model_args = ClassificationArgs()\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.output_dir = '/content/drive/MyDrive/NLP hva så/ASD_classification/out/cool_model'\n",
    "#model_args.manual_seed = 4  # comment out if cross-validating\n",
    "model_args.use_multiprocessing = True\n",
    "model_args.train_batch_size = 16\n",
    "model_args.eval_batch_size = 8\n",
    "model_args.save_best_model = True\n",
    "model_args.wandb_project = \"Parameter Sweep5\"\n",
    "\n",
    "def training_model():\n",
    "    # set k_fold-specifics\n",
    "    n = 5\n",
    "    seed = 43\n",
    "    kf = KFold(n_splits=n, random_state = seed, shuffle=True)\n",
    "\n",
    "    # Defining Model using k-folds\n",
    "    results = []\n",
    "    val_train = []\n",
    "    for train_index, val_index in kf.split(train_data):\n",
    "        # Initialize a new wandb run\n",
    "        wandb.init()\n",
    "        # splitting Dataframe (dataset not included)\n",
    "        train_df = train_data.iloc[train_index]\n",
    "        val_df = train_data.iloc[val_index]\n",
    "        # Defining Model\n",
    "        model = ClassificationModel('bert', 'bert-base-uncased', use_cuda=True, args=model_args, num_labels = 2, weight=[0.4, 0.6], \n",
    "                                    sweep_config=wandb.config)\n",
    "        # train the model\n",
    "        model.train_model(train_df, eval_df = val_df)\n",
    "        # validate the model\n",
    "        result, model_outputs, wrong_predictions = model.eval_model(val_df, acc=accuracy_score) # , acc = accuracy_score\n",
    "        print(result['acc'])\n",
    "        # append model score\n",
    "        results.append(result['acc'])\n",
    "\n",
    "        # sync wandb\n",
    "        wandb.join()\n",
    "\n",
    "# refer the model to the wandb id\n",
    "wandb.agent(sweep_id, training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that saves the model\n",
    "def saveModel(model): \n",
    "    \"\"\" function to save model after training\n",
    "    Args:\n",
    "        model (Module): pytorch model to be saved\n",
    "    \"\"\"\n",
    "    path = os.path.join(\"/Users\", \"kristian\", \"Documents\", \"Skole\", \"7. semester\", \"NLP\", \"Exam\", \"ASD_classification\", + \"BERT\" + \".pth\")\n",
    "    torch.save(model, path)\n",
    "\n",
    "# saving model manually\n",
    "saveModel(model = model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output result \n",
    "result, model_outputs, wrong_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playing around with the model making it make predictions on random sentence\n",
    "model.predict(['I like ice cream'])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
